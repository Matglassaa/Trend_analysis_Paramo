{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba279b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09edcdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stations: 4\n",
      "Example stations: {'type': 'FeatureCollection', 'columns': {'station_id': 'String'}, 'features': [{'type': 'Feature', 'geometry': {'type': 'Point', 'coordinates': [-79.234708, -3.062612]}, 'id': '1_2_00000000000000000000', 'properties': {'asset': 'Zhurucay', 'name': 'Zhurucay_monitoring', 'site': 'Zhurucay_monitoring', 'site2': 'Zhurucay:Zhurucay_monitoring', 'station_id': 'Zhurucay_monitoring'}}, {'type': 'Feature', 'geometry': {'type': 'Point', 'coordinates': [-79.22222577105055, -2.7831219944997074]}, 'id': '2_00000000000000000000', 'properties': {'Altura': 3962, 'Codigo': 'QP1', 'Tipo': 'Precipitation', 'X': 697621.9592, 'Y': 9692230.0653, 'asset': 'Quinuas', 'site': 'QP1', 'site2': 'Quinuas:QP1', 'station_id': 'QP1'}}, {'type': 'Feature', 'geometry': {'type': 'Point', 'coordinates': [-79.1931133268206, -2.782269566783723]}, 'id': '2_00000000000000000001', 'properties': {'Altura': 3633, 'Codigo': 'QP2', 'Tipo': 'Precipitation', 'X': 701109.1811, 'Y': 9692380.1398, 'asset': 'Quinuas', 'site': 'QP2', 'site2': 'Quinuas:QP2', 'station_id': 'QP2'}}]}\n",
      "[ERA5] year window has data: True\n",
      "[MERRA] year window has data: True\n",
      "[GLDAS] year window has data: True\n"
     ]
    },
    {
     "ename": "EEException",
     "evalue": "User memory limit exceeded.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Jelle Gortemaker\\miniconda3\\envs\\mude-base\\Lib\\site-packages\\ee\\data.py:349\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[1;34m(call, num_retries)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mexecute(num_retries\u001b[38;5;241m=\u001b[39mnum_retries)\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Jelle Gortemaker\\miniconda3\\envs\\mude-base\\Lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jelle Gortemaker\\miniconda3\\envs\\mude-base\\Lib\\site-packages\\googleapiclient\\http.py:938\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError(resp, content, uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri)\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostproc(resp, content)\n",
      "\u001b[1;31mHttpError\u001b[0m: <HttpError 400 when requesting https://earthengine.googleapis.com/v1/projects/cuenca-soil-moisture/value:compute?prettyPrint=false&alt=json returned \"User memory limit exceeded.\". Details: \"User memory limit exceeded.\">",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mEEException\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 332\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarted export: DAYTIME_Radiation_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_int\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m years_py:\n\u001b[1;32m--> 332\u001b[0m     export_year(y)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll yearly exports started. Monitor Tasks panel or use ee.batch.Task.list().\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 317\u001b[0m, in \u001b[0;36mexport_year\u001b[1;34m(y_int)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[0;32m    316\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m {name: fc\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mgetInfo() \u001b[38;5;28;01mfor\u001b[39;00m name, fc \u001b[38;5;129;01min\u001b[39;00m daily_named}\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYear \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_int\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sizes:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sizes, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwide:\u001b[39m\u001b[38;5;124m\"\u001b[39m, wide\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mgetInfo())\n\u001b[0;32m    318\u001b[0m     first \u001b[38;5;241m=\u001b[39m wide\u001b[38;5;241m.\u001b[39mfirst()\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m first:\n",
      "File \u001b[1;32mc:\\Users\\Jelle Gortemaker\\miniconda3\\envs\\mude-base\\Lib\\site-packages\\ee\\computedobject.py:107\u001b[0m, in \u001b[0;36mComputedObject.getInfo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetInfo\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Fetch and return information about this object.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m    The object can evaluate to anything.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcomputeValue(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Jelle Gortemaker\\miniconda3\\envs\\mude-base\\Lib\\site-packages\\ee\\data.py:1064\u001b[0m, in \u001b[0;36mcomputeValue\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m   1061\u001b[0m body \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpression\u001b[39m\u001b[38;5;124m'\u001b[39m: serializer\u001b[38;5;241m.\u001b[39mencode(obj, for_cloud_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)}\n\u001b[0;32m   1062\u001b[0m _maybe_populate_workload_tag(body)\n\u001b[1;32m-> 1064\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _execute_cloud_call(\n\u001b[0;32m   1065\u001b[0m     _get_cloud_projects()\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;241m.\u001b[39mvalue()\n\u001b[0;32m   1067\u001b[0m     \u001b[38;5;241m.\u001b[39mcompute(body\u001b[38;5;241m=\u001b[39mbody, project\u001b[38;5;241m=\u001b[39m_get_projects_path(), prettyPrint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1068\u001b[0m )[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Jelle Gortemaker\\miniconda3\\envs\\mude-base\\Lib\\site-packages\\ee\\data.py:351\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[1;34m(call, num_retries)\u001b[0m\n\u001b[0;32m    349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mexecute(num_retries\u001b[38;5;241m=\u001b[39mnum_retries)\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 351\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "\u001b[1;31mEEException\u001b[0m: User memory limit exceeded."
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Daily *daytime-only* radiation over monitoring sites → wide CSV by year (Python + Earth Engine)\n",
    "\n",
    "Generic, memory-lean approach:\n",
    "- Register each sensor in SENSORS with: collection id, band names, units (\"J_hour\" or \"W\"),\n",
    "  slice duration (seconds per image, for W→J), a daytime mask band (SWdown-like), and a min buffer radius.\n",
    "- For each sensor & day:\n",
    "  * Build one masked day-collection (daytime only: SWdown > 0).\n",
    "  * Sum daily energy for SWdown and Rn (SWnet+LWnet), convert to MJ.\n",
    "  * Reduce the 2-band image over small station buffers (no .clip) → columns per station.\n",
    "- Join all sensors by 'date' into a wide per-year table and export CSV.\n",
    "\n",
    "Edit these blocks as needed:\n",
    "- MONITOR_ASSET_IDS\n",
    "- START / END\n",
    "- SENSORS (add/modify sensors)\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "# ee.Authenticate()  # run once per machine if needed\n",
    "ee.Initialize(project=\"cuenca-soil-moisture\")\n",
    "\n",
    "# ----------------------------- CONFIG -----------------------------\n",
    "MONITOR_ASSET_IDS = [\n",
    "    \"projects/cuenca-soil-moisture/assets/Zhurucay_monitoring\",\n",
    "    \"projects/cuenca-soil-moisture/assets/Quinuas_monitoring\",\n",
    "]\n",
    "\n",
    "START = ee.Date(\"2016-01-01\")\n",
    "END   = ee.Date(\"2025-04-30\")\n",
    "\n",
    "DEBUG = True\n",
    "TILE_SCALE = 2   # bump to 3–4 if you hit memory issues\n",
    "\n",
    "# Sensor registry (add more following the same schema)\n",
    "SENSORS = [\n",
    "    dict(\n",
    "        name=\"ERA5\",\n",
    "        collection=\"ECMWF/ERA5_LAND/HOURLY\",\n",
    "        bands=dict(\n",
    "            SWdown=\"surface_solar_radiation_downwards\",  # J m^-2 per hour\n",
    "            SWnet =\"surface_net_solar_radiation\",        # J m^-2 per hour\n",
    "            LWnet =\"surface_net_thermal_radiation\"       # J m^-2 per hour\n",
    "        ),\n",
    "        units=\"J_hour\",       # already energy per hour (J)\n",
    "        dt_s=None,            # not used for J_hour\n",
    "        min_buffer_m=2000,\n",
    "        sw_mask_band=\"surface_solar_radiation_downwards\"\n",
    "    ),\n",
    "    dict(\n",
    "        name=\"MERRA\",\n",
    "        collection=\"NASA/GSFC/MERRA/rad/2\",\n",
    "        bands=dict(\n",
    "            SWdown=\"SWGDN\",   # W m^-2 (hourly mean)\n",
    "            SWnet =\"SWGNT\",   # W m^-2\n",
    "            LWnet =\"LWGNT\"    # W m^-2\n",
    "        ),\n",
    "        units=\"W\",           # power → multiply by dt_s to get energy (J)\n",
    "        dt_s=3600,           # seconds per slice\n",
    "        min_buffer_m=12000,\n",
    "        sw_mask_band=\"SWGDN\"\n",
    "    ),\n",
    "    dict(\n",
    "        name=\"GLDAS\",\n",
    "        collection=\"NASA/GLDAS/V021/NOAH/G025/T3H\",\n",
    "        bands=dict(\n",
    "            SWdown=\"SWdown_f_tavg\",  # W m^-2 (3-hour mean)\n",
    "            SWnet =\"Swnet_tavg\",     # W m^-2\n",
    "            LWnet =\"Lwnet_tavg\"      # W m^-2\n",
    "        ),\n",
    "        units=\"W\",\n",
    "        dt_s=3*3600,         # seconds per 3-hour slice\n",
    "        min_buffer_m=20000,\n",
    "        sw_mask_band=\"SWdown_f_tavg\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# ----------------------------- HELPERS -----------------------------\n",
    "def sanitize_id(s: ee.String) -> ee.String:\n",
    "    \"\"\"Short, safe identifier for CSV suffixes.\"\"\"\n",
    "    s = ee.String(s).replace(\"[^A-Za-z0-9_]\", \"_\", \"g\")\n",
    "    starts_digit = s.match(\"^[0-9]\").length().gt(0)\n",
    "    s = ee.String(ee.Algorithms.If(starts_digit, ee.String(\"st_\").cat(s), s))\n",
    "    s = s.replace(\"_+\", \"_\", \"g\").slice(0, 40)\n",
    "    return ee.String(ee.Algorithms.If(s.length().gt(0), s, \"st_unknown\"))\n",
    "\n",
    "def pick_site_name(f: ee.Feature) -> ee.String:\n",
    "    \"\"\"Robust site name from common properties; fallback to feature id.\"\"\"\n",
    "    p = f.propertyNames()\n",
    "    return ee.String(\n",
    "        ee.Algorithms.If(\n",
    "            p.contains(\"site\"), f.get(\"site\"),\n",
    "            ee.Algorithms.If(\n",
    "                p.contains(\"Codigo\"), f.get(\"Codigo\"),\n",
    "                ee.Algorithms.If(p.contains(\"name\"), f.get(\"name\"), f.id())\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "def list_days(start: ee.Date, end: ee.Date) -> ee.List:\n",
    "    \"\"\"List of {'day': d, 'next': d+1} covering [start, end] inclusive.\"\"\"\n",
    "    end_excl = end.advance(1, \"day\")\n",
    "    n = end_excl.difference(start, \"day\")\n",
    "    return ee.List.sequence(0, n.subtract(1)).map(\n",
    "        lambda i: ee.Dictionary({\n",
    "            \"day\":  start.advance(ee.Number(i), \"day\"),\n",
    "            \"next\": start.advance(ee.Number(i), \"day\").advance(1, \"day\"),\n",
    "        })\n",
    "    )\n",
    "\n",
    "def product_buffers(stations_fc: ee.FeatureCollection, sample_img: ee.Image, min_meters: int) -> ee.FeatureCollection:\n",
    "    \"\"\"\n",
    "    Buffer each station by max(0.6 * native pixel size, min_meters).\n",
    "    Copy original properties so 'station_id' stays available in reductions.\n",
    "    \"\"\"\n",
    "    scale = ee.Number(ee.Image(sample_img).projection().nominalScale())\n",
    "    r = scale.multiply(0.6).max(ee.Number(min_meters))\n",
    "    return stations_fc.map(lambda f: ee.Feature(ee.Feature(f).geometry().buffer(r)).copyProperties(f)) \\\n",
    "                      .set({\"buffer_m\": r, \"scale_m\": scale})\n",
    "\n",
    "def reduce_to_dict_by_station(img: ee.Image,\n",
    "                              fc_buffers: ee.FeatureCollection,\n",
    "                              scale_num: float,\n",
    "                              band_list: ee.List) -> ee.Dictionary:\n",
    "    \"\"\"\n",
    "    Reduce image over each buffer, returning a flat dictionary:\n",
    "      { <band>_<stationId>: mean, ... }\n",
    "    \"\"\"\n",
    "    col = img.select(band_list).reduceRegions(\n",
    "        collection=fc_buffers,\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        scale=scale_num,\n",
    "        tileScale=TILE_SCALE\n",
    "    )\n",
    "    feats = col.toList(col.size())\n",
    "\n",
    "    def _accum(i, acc):\n",
    "        f = ee.Feature(feats.get(i))\n",
    "        sid = ee.String(f.get(\"station_id\"))\n",
    "        def _one_band(k, acc2):\n",
    "            k = ee.String(k)\n",
    "            has_k = f.propertyNames().contains(k)\n",
    "            add_if = ee.Dictionary(\n",
    "                ee.Algorithms.If(\n",
    "                    has_k,\n",
    "                    ee.Dictionary().set(k.cat(\"_\").cat(sid), f.get(k)),\n",
    "                    ee.Dictionary({})\n",
    "                )\n",
    "            )\n",
    "            return ee.Dictionary(acc2).combine(add_if, True)\n",
    "        per_station = ee.List(band_list).iterate(_one_band, ee.Dictionary({}))\n",
    "        return ee.Dictionary(acc).combine(ee.Dictionary(per_station), True)\n",
    "\n",
    "    return ee.Dictionary(ee.List.sequence(0, feats.size().subtract(1)).iterate(_accum, ee.Dictionary({})))\n",
    "\n",
    "def feat_from_dict(date: ee.Date, dct: ee.Dictionary, tag: str) -> ee.Feature:\n",
    "    \"\"\"Wrap the per-day dictionary into a feature row with 'date' and 'tag'.\"\"\"\n",
    "    return ee.Feature(\n",
    "        None,\n",
    "        ee.Dictionary(dct).set(\"date\", ee.Date(date).format(\"YYYY-MM-dd\")).set(\"tag\", tag)\n",
    "    )\n",
    "\n",
    "def inner_join_by_date(fc_a: ee.FeatureCollection, fc_b: ee.FeatureCollection) -> ee.FeatureCollection:\n",
    "    \"\"\"Inner-join two tables by 'date' and merge properties.\"\"\"\n",
    "    join = ee.Join.inner()\n",
    "    flt  = ee.Filter.equals(leftField=\"date\", rightField=\"date\")\n",
    "    joined = join.apply(fc_a, fc_b, flt)\n",
    "    def _merge(row):\n",
    "        row = ee.Feature(row)\n",
    "        a = ee.Feature(row.get(\"primary\"))\n",
    "        b = ee.Feature(row.get(\"secondary\"))\n",
    "        merged = ee.Dictionary(a.toDictionary()).combine(b.toDictionary(), True)\n",
    "        return ee.Feature(None, merged)\n",
    "    return ee.FeatureCollection(joined.map(_merge))\n",
    "\n",
    "# ----------------------------- STATIONS -----------------------------\n",
    "def load_stations(asset_id: str, asset_label: str) -> ee.FeatureCollection:\n",
    "    fc = ee.FeatureCollection(asset_id)\n",
    "    def _map(f):\n",
    "        site = pick_site_name(f)\n",
    "        site2 = ee.String(asset_label).cat(\":\").cat(site)\n",
    "        return ee.Feature(f.geometry(), f.toDictionary()).set({\n",
    "            \"site\": site,\n",
    "            \"asset\": asset_label,\n",
    "            \"site2\": site2\n",
    "        })\n",
    "    return fc.map(_map)\n",
    "\n",
    "stations = (ee.FeatureCollection([])\n",
    "            .merge(load_stations(MONITOR_ASSET_IDS[0], \"Zhurucay\"))\n",
    "            .merge(load_stations(MONITOR_ASSET_IDS[1], \"Quinuas\"))\n",
    "            .map(lambda f: ee.Feature(f).set({\"station_id\": sanitize_id(ee.String(f.get(\"site\")))})))\n",
    "\n",
    "if DEBUG:\n",
    "    print(\"Stations:\", stations.size().getInfo())\n",
    "    print(\"Example stations:\", stations.limit(3).getInfo())\n",
    "\n",
    "# ----------------------------- GENERIC DAILY BUILDER -----------------------------\n",
    "def daily_daytime_fc(sensor: dict, y_start: ee.Date, y_end: ee.Date) -> ee.FeatureCollection:\n",
    "    \"\"\"\n",
    "    For one sensor over [y_start, y_end], produce per-day rows with columns:\n",
    "      <SENSOR>_day_SWdown_MJ_<station>,  <SENSOR>_day_Rn_MJ_<station>\n",
    "    Memory-lean: one masked day-collection reused for SWdown and Rn.\n",
    "    \"\"\"\n",
    "    name   = sensor[\"name\"]\n",
    "    bands  = sensor[\"bands\"]\n",
    "    units  = sensor[\"units\"]\n",
    "    dt_s   = sensor[\"dt_s\"]\n",
    "    collid = sensor[\"collection\"]\n",
    "    swmask = sensor[\"sw_mask_band\"]\n",
    "    minbuf = sensor[\"min_buffer_m\"]\n",
    "\n",
    "    # Pre-filter for the year window (+1 day for end-exclusive)\n",
    "    ic_base = (ee.ImageCollection(collid)\n",
    "               .filterDate(y_start, y_end.advance(1, \"day\"))\n",
    "               .select([bands[\"SWdown\"], bands[\"SWnet\"], bands[\"LWnet\"]]))\n",
    "\n",
    "    sample = ic_base.first()\n",
    "    # Return empty FC fast if no data\n",
    "    if DEBUG:\n",
    "        print(f\"[{name}] year window has data:\", bool(sample.getInfo() is not None))\n",
    "\n",
    "    return ee.FeatureCollection(\n",
    "        ee.Algorithms.If(\n",
    "            sample,\n",
    "            (lambda _sample=sample: (\n",
    "                # Compute scale (client) and buffers once per sensor/year\n",
    "                (lambda scale_num, fc_buf, buf_geom:\n",
    "                    ee.FeatureCollection(\n",
    "                        list_days(y_start, y_end).map(\n",
    "                            lambda d: _per_day_row(\n",
    "                                name, bands, units, dt_s,\n",
    "                                ic_base,\n",
    "                                ee.Date(ee.Dictionary(d).get(\"day\")),\n",
    "                                ee.Date(ee.Dictionary(d).get(\"next\")),\n",
    "                                swmask,\n",
    "                                fc_buf, buf_geom,\n",
    "                                scale_num\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                )(\n",
    "                    float(ee.Image(_sample).projection().nominalScale().getInfo()),\n",
    "                    product_buffers(stations, _sample, minbuf),\n",
    "                    product_buffers(stations, _sample, minbuf).geometry()\n",
    "                )\n",
    "            ))(),\n",
    "            ee.FeatureCollection([])  # no data in this year/sensor\n",
    "        )\n",
    "    )\n",
    "\n",
    "def _per_day_row(name, bands, units, dt_s,\n",
    "                 ic_base, day: ee.Date, nxt: ee.Date,\n",
    "                 swmask: str,\n",
    "                 fc_buf: ee.FeatureCollection, buf_geom: ee.Geometry,\n",
    "                 scale_num: float) -> ee.Feature:\n",
    "    \"\"\"\n",
    "    Build one per-day feature for a sensor:\n",
    "      - Mask daytime (SWdown > 0)\n",
    "      - Sum SWdown and (SWnet+LWnet), convert to MJ\n",
    "      - Reduce over buffers → dictionary\n",
    "      - Wrap into a feature row with 'date'\n",
    "    \"\"\"\n",
    "    # One masked day-collection reused\n",
    "    day_ic_masked = (ic_base.filterDate(day, nxt)\n",
    "                           .filterBounds(buf_geom)\n",
    "                           .map(lambda im: ee.Image(im).updateMask(ee.Image(im).select(swmask).gt(0))))\n",
    "\n",
    "    # SWdown daily energy\n",
    "    sw_sum = day_ic_masked.select(bands[\"SWdown\"]).sum()\n",
    "    if units == \"J_hour\":\n",
    "        sw_mj = sw_sum.divide(1e6)  # J → MJ\n",
    "    else:  # \"W\"\n",
    "        sw_mj = sw_sum.multiply(dt_s).divide(1e6)  # W * s → J → MJ\n",
    "    sw_mj = sw_mj.rename(f\"{name}_day_SWdown_MJ\")\n",
    "\n",
    "    # Rn daily energy = (SWnet + LWnet)\n",
    "    rn_sum = day_ic_masked.select(bands[\"SWnet\"]).sum().add(day_ic_masked.select(bands[\"LWnet\"]).sum())\n",
    "    if units == \"J_hour\":\n",
    "        rn_mj = rn_sum.divide(1e6)\n",
    "    else:\n",
    "        rn_mj = rn_sum.multiply(dt_s).divide(1e6)\n",
    "    rn_mj = rn_mj.rename(f\"{name}_day_Rn_MJ\")\n",
    "\n",
    "    img = ee.Image.cat([sw_mj, rn_mj]).set(\"system:time_start\", day.millis())\n",
    "\n",
    "    dct = reduce_to_dict_by_station(img, fc_buf, scale_num, img.bandNames())\n",
    "    return feat_from_dict(day, dct, f\"{name}_DAY\")\n",
    "\n",
    "# ----------------------------- YEAR LOOP & EXPORT -----------------------------\n",
    "start_year = int(START.get(\"year\").getInfo())\n",
    "end_year   = int(END.get(\"year\").getInfo())\n",
    "years_py   = list(range(start_year, end_year + 1))\n",
    "\n",
    "def export_year(y_int: int):\n",
    "    y_start_ee = ee.Date.fromYMD(y_int, 1, 1)\n",
    "    y_end_ee   = ee.Date.fromYMD(y_int, 12, 31)\n",
    "\n",
    "    # Clip to [START, END]\n",
    "    y_start = ee.Date(ee.Algorithms.If(y_start_ee.millis().lt(START.millis()), START, y_start_ee))\n",
    "    y_end   = ee.Date(ee.Algorithms.If(y_end_ee.millis().gt(END.millis()),   END,   y_end_ee))\n",
    "\n",
    "    # Build daily tables per sensor\n",
    "    daily_named = []\n",
    "    for sensor in SENSORS:\n",
    "        fc = daily_daytime_fc(sensor, y_start, y_end)\n",
    "        daily_named.append((sensor[\"name\"], ee.FeatureCollection(fc)))\n",
    "\n",
    "    # Use the first sensor as base; inner-join others by date\n",
    "    base_name, wide = daily_named[0]\n",
    "    for name, fc in daily_named[1:]:\n",
    "        wide = inner_join_by_date(wide, fc)\n",
    "\n",
    "    if DEBUG:\n",
    "        sizes = {name: fc.size().getInfo() for name, fc in daily_named}\n",
    "        print(f\"Year {y_int} sizes:\", sizes, \"wide:\", wide.size().getInfo())\n",
    "        first = wide.first()\n",
    "        if first:\n",
    "            print(\"Fields sample:\", ee.Feature(first).propertyNames().getInfo())\n",
    "\n",
    "    task = ee.batch.Export.table.toDrive(\n",
    "        collection=wide,\n",
    "        description=f\"DAYTIME_Radiation_{y_int}\",\n",
    "        folder=\"GoogleEarthEngine\",\n",
    "        fileFormat=\"CSV\",\n",
    "    )\n",
    "    task.start()\n",
    "    print(f\"Started export: DAYTIME_Radiation_{y_int}\")\n",
    "\n",
    "for y in years_py:\n",
    "    export_year(y)\n",
    "\n",
    "print(\"All yearly exports started. Monitor Tasks panel or use ee.batch.Task.list().\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mude-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
